{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023年度 深層学習演習 最終課題\n",
    "## 23vr008n 高林 秀\n",
    "\n",
    "## 問題設定\n",
    "### 選択した課題\n",
    "* (a) : テーブルデータ、画像データ、系列データのいずれか(※ 広い意味で捉えて良い) を用意し、回帰もしくは分類タスクを設定して深層学習モデルにより学習、評価を行え。よりよい結果が得られるよう試行錯誤し、過程も含めて示すこと。 \n",
    "### 設定したタスク\n",
    "* ポケモンの画像分類-オーキドモデルを作る-\n",
    " * 下記データセットを使用する。\n",
    " * 149クラスある\n",
    "* https://www.kaggle.com/datasets/echometerhhwl/pokemon-gen-1-38914\n",
    "\n",
    "## データセットについて\n",
    "学習で使うデータセットはkaggleからダウンロードしたものを使用する。\n",
    "\n",
    "このデータは、**149種類のポケモンの画像**が入っている。アニメ画像の切り抜きや、手書きで描いたポケモンの画像などが含まれている。\n",
    "\n",
    "各ポケモン毎にフォルダが分かれており、その中に画像が入っている。\n",
    "画像の層数は全部で**35627枚**である。\n",
    "\n",
    "## 使用するモデルについて\n",
    "本課題では事前学習済みのモデルをファインチューニングすることで、モデルを作成する。\n",
    "\n",
    "今回使用するモデルは以下の通りである。\n",
    "* モデル名：EfficientNetV2\n",
    "* TODO: モデルの説明を書く\n",
    "\n",
    "## 評価方法\n",
    "ダウンロードしたデータセットを、学習用とテストセットに分け、テストセットを用いて評価を行う。\n",
    "\n",
    "なお、評価方法は、**Accuracy**を用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行環境\n",
    "本稿で作成したモデルは、ローカルマシン上で構築した。以下に実行環境を示す。\n",
    "\n",
    "* OS: Windows 11\n",
    "* CPU: Intel(R) Core(TM) i7-13700H @ 2.40GHz\n",
    "* GPU: NVIDIA GeForce RTX 4060 Laptop GPU @ 8GB\n",
    "* RAM: 32GB\n",
    "* 開発環境\n",
    "    * Python 3.9.6\n",
    "    * PyTorch 1.9.1 + cu111\n",
    "    * Torchvision 0.10.1 + cu111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルデータの表示\n",
    "学習データで使用する画像は次のようなもので、単純にポケモンのみが写っているものもあれば、背景に人間が写っているものや、手書きのもの、カード状のものまで様々である。\n",
    "\n",
    "<img src=\"archive/data/Raichu/0c7e0a91bf65facbbc2d2c06b55f1bf2.jpg\" style=\"width: 250px;\"/>\n",
    "<img src=\"archive/data/Raichu/ee730b7e1e47a1aafd94476016875344.jpg\" style=\"width: 250px;\"/>\n",
    "<img src=\"archive/data/Vileplume/0ac8fd551dd66cda9f03e6124363b071.png\" style=\"width: 250px;\"/>\n",
    "<img src=\"archive/data/Zapdos/0b3cf9fd603a437e50e76222ce0db245.jpg\" style=\"width: 250px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装/モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDAが有効化どうかの確認\n",
    "print(f\"CUDA is Available : {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"archive/data\"\n",
    "\n",
    "# 画像の前処理（リサイズ、テンソル変換など）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#各画像が格納されたサブディレクトリの名前をクラス名として扱う。\n",
    "all_dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform) #datasets.ImageFolderは、自動的にサブディレクトリをクラス名として扱う。\n",
    "\n",
    "TOTAL_SIZE = len(all_dataset)\n",
    "print(f\"TOTAL_SIZE = {TOTAL_SIZE}\")\n",
    "USE_SIZE = TOTAL_SIZE\n",
    "print(f\"USE_SIZE = {USE_SIZE}\")\n",
    "\n",
    "\n",
    "dataset, _ = random_split(all_dataset, [USE_SIZE, TOTAL_SIZE - USE_SIZE])\n",
    "\n",
    "TRAIN_RATO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "\n",
    "train_size = int(USE_SIZE * TRAIN_RATO)\n",
    "val_size = int(USE_SIZE * VAL_RATIO)\n",
    "test_size = int(USE_SIZE - train_size - val_size)\n",
    "split_size = [train_size, val_size, test_size]\n",
    "print(f\"split_size ={split_size}\")\n",
    "print(f\"sum = {sum(split_size)}\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Class = {all_dataset.classes}\")\n",
    "print(f\"Class Size = {len(all_dataset.classes)}\")\n",
    "\n",
    "CLASS_SIZE = len(all_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(30, 30))\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i < 9:  # 最初の9枚の画像のみ表示\n",
    "        img = images[0]\n",
    "        label = labels[0]\n",
    "        ax = axs[i // 3, i % 3]\n",
    "        ax.imshow(img.permute(1, 2, 0))  # チャンネル次元の順序を変更\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #NOTE:調べたところtorchで読み込むとPILの画像破損判定に引っかかる。強制的に読み込む。\n",
    "def show_distribution(loader, title=\"\") -> list[int]:\n",
    "    count = [0] * CLASS_SIZE\n",
    "    for _, label in tqdm(loader, desc=\"Generating Distribution...\"):\n",
    "        for l in label:\n",
    "            count[l] += 1\n",
    "    plt.bar(range(CLASS_SIZE), count)\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return count\n",
    "\n",
    "train_dist = show_distribution(train_loader, \"TrainData Distribution\")\n",
    "test_dist = show_distribution(test_loader, \"TestData Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ダウンサンプリング\n",
    "\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.indices = self.balance_classes()\n",
    "\n",
    "    def balance_classes(self):\n",
    "        # 各クラスのインデックスを格納する\n",
    "        class_indices = defaultdict(list)\n",
    "        for idx, (_, label) in tqdm(enumerate(self.dataset), desc=\"Collectioning Index...\"):\n",
    "            class_indices[label].append(idx)\n",
    "\n",
    "        min_size = min(len(indices) for indices in class_indices.values())\n",
    "\n",
    "        # 各クラスからランダムにmin_size個のインデックスを選択\n",
    "        balanced_indices = []\n",
    "        for indices in tqdm(class_indices.values(), desc=\"Down Sampling...\"):\n",
    "            balanced_indices.extend(np.random.choice(indices, min_size, replace=False))\n",
    "\n",
    "        return balanced_indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "d_sampled_dataset = BalancedDataset(all_dataset)\n",
    "print(f\"down sampled_dataset size = {len(d_sampled_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ローダーの再定義\n",
    "\n",
    "train_size = int(len(d_sampled_dataset) * TRAIN_RATO)\n",
    "val_size = int(len(d_sampled_dataset) * VAL_RATIO)\n",
    "test_size = int(len(d_sampled_dataset) - train_size - val_size)\n",
    "split_size = [train_size, val_size, test_size]\n",
    "print(f\"split_size ={split_size}\")\n",
    "\n",
    "d_sampled_train_dataset, d_sampled_val_dataset, d_sampled_test_dataset = random_split(d_sampled_dataset, split_size)\n",
    "\n",
    "d_sampled_train_loader = DataLoader(d_sampled_train_dataset, batch_size=32, shuffle=True)\n",
    "d_sampled_val_loader = DataLoader(d_sampled_val_dataset, batch_size=32, shuffle=False)\n",
    "d_sampled_test_loader = DataLoader(d_sampled_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "d_sampled_train_dist = show_distribution(d_sampled_train_loader, \"Down Sampled TrainData Distribution\")\n",
    "d_sampled_test_dist = show_distribution(d_sampled_test_loader, \"Down Sampled TestData Distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルのロード\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=CLASS_SIZE, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    # 訓練フェーズ\n",
    "    for idx, [inputs, labels] in enumerate(d_sampled_test_loader):  # train_loaderはトレーニングデータのローダー\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        print(\"Training iteration: \", idx+1, end=\"\\r\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = calculate_accuracy(model, d_sampled_val_loader)\n",
    "    print(f\"Epoch {epoch}: accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの保存\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "save_model(model, \"./Models/20240129.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
